{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imoport the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# import sklearn libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  load data\n",
    "\n",
    "iris_df = pd.read_csv('../data/iris.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There isn't much to do to transfrom the data, what we can do is to remove the highly correlated features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should first choose our model, We will try three different models: SVM, Logistic Regression and KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4) (30, 4) (120,) (30,)\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "\n",
    "X = iris_df.drop(['species'], axis=1)\n",
    "\n",
    "y = iris_df['species']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_class_scores(y_test, y_pred):\n",
    "    print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "    print('Precision: ', precision_score(y_test, y_pred, average='weighted'))\n",
    "    print('Recall: ', recall_score(y_test, y_pred, average='weighted'))\n",
    "    print('F1: ', f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set scores:\n",
      "Accuracy:  0.975\n",
      "Precision:  0.9751928288513655\n",
      "Recall:  0.975\n",
      "F1:  0.9749960931395532\n",
      "Test set scores:\n",
      "Accuracy:  1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "F1:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "\n",
    "model = SVC(kernel='linear')\n",
    "\n",
    "steps = [('scaler', StandardScaler()), ('model', model)]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# evaluate on train set\n",
    "\n",
    "y_pred = pipeline.predict(X_train)\n",
    "\n",
    "print('Train set scores:')\n",
    "\n",
    "print_class_scores(y_train, y_pred)\n",
    "\n",
    "# evaluate on test set\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print('Test set scores:')\n",
    "\n",
    "print_class_scores(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those are great results, let's see if we can improve them with a randomized search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2988.35s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "2988.58s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "2988.81s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "2989.04s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "2989.28s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "2989.50s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "2989.73s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "2989.96s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "2990.20s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "2990.43s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "2990.67s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "2990.90s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "2991.13s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "2991.36s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "2991.60s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "2991.83s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set scores:\n",
      "Accuracy:  0.975\n",
      "Precision:  0.9751928288513655\n",
      "Recall:  0.975\n",
      "F1:  0.9749960931395532\n",
      "Test set scores:\n",
      "Accuracy:  1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "F1:  1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model__kernel': 'linear',\n",
       " 'model__gamma': 0.001,\n",
       " 'model__degree': 2,\n",
       " 'model__coef0': 2,\n",
       " 'model__class_weight': None,\n",
       " 'model__C': 1}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randomized search\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# define parameter grid\n",
    "\n",
    "# params to tune for svm\n",
    "\n",
    "param_grid = {\n",
    "    'model__C': [0.1, 1, 10],            # Regularization parameter\n",
    "    'model__kernel': ['linear', 'rbf'],  # Kernel type\n",
    "    'model__gamma': [0.001, 0.01, 0.1],  # Kernel coefficient (for 'rbf' and 'poly')\n",
    "    'model__degree': [2, 3, 4],          # Polynomial degree (for 'poly')\n",
    "    'model__coef0': [0, 1, 2],           # Coefficient 0 (for 'poly' and 'sigmoid')\n",
    "    'model__class_weight': [None, 'balanced'],  # Class weights\n",
    "}\n",
    "\n",
    "# define randomized search\n",
    "\n",
    "random_search = RandomizedSearchCV(pipeline, param_grid, cv=3, n_jobs=-1, verbose=1, scoring='accuracy', n_iter=30)\n",
    "\n",
    "# fit model\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# train set scores\n",
    "\n",
    "y_pred = random_search.predict(X_train)\n",
    "\n",
    "print('Train set scores:')\n",
    "\n",
    "print_class_scores(y_train, y_pred)\n",
    "\n",
    "# test set scores\n",
    "\n",
    "y_pred = random_search.predict(X_test)\n",
    "\n",
    "print('Test set scores:')\n",
    "\n",
    "print_class_scores(y_test, y_pred)\n",
    "\n",
    "# best params\n",
    "\n",
    "random_search.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have the same results, so probably that's the best we can do with a SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set scores:\n",
      "Accuracy:  0.9583333333333334\n",
      "Precision:  0.9585157390035438\n",
      "Recall:  0.9583333333333334\n",
      "F1:  0.9583268218992551\n",
      "Test set scores:\n",
      "Accuracy:  0.9333333333333333\n",
      "Precision:  0.9333333333333333\n",
      "Recall:  0.9333333333333333\n",
      "F1:  0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "#  Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# define model\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "steps = [('scaler', StandardScaler()), ('model', model)]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# evaluate on train set\n",
    "\n",
    "y_pred = pipeline.predict(X_train)\n",
    "\n",
    "print('Train set scores:')\n",
    "\n",
    "print_class_scores(y_train, y_pred)\n",
    "\n",
    "# evaluate on test set\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print('Test set scores:')\n",
    "\n",
    "print_class_scores(y_test, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have good results even with a simple logistic regression, let's see if we can improve them with a randomized search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Train set scores:\n",
      "Accuracy:  0.975\n",
      "Precision:  0.9751928288513655\n",
      "Recall:  0.975\n",
      "F1:  0.9749960931395532\n",
      "Test set scores:\n",
      "Accuracy:  1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "F1:  1.0\n"
     ]
    }
   ],
   "source": [
    "# randomized search\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# define parameter grid logistic regression\n",
    "\n",
    "param_grid = {\n",
    "    'model__penalty': ['l1', 'l2'],  # Regularization type\n",
    "    'model__C': [0.1, 1, 10],        # Regularization parameter\n",
    "    'model__class_weight': [None, 'balanced'],  # Class weights\n",
    "}\n",
    "\n",
    "# define randomized search\n",
    "\n",
    "random_search = RandomizedSearchCV(pipeline, param_grid, cv=3, n_jobs=-1, verbose=1, scoring='accuracy', n_iter=10)\n",
    "\n",
    "# fit model\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# train set scores\n",
    "\n",
    "y_pred = random_search.predict(X_train)\n",
    "\n",
    "print('Train set scores:')\n",
    "\n",
    "print_class_scores(y_train, y_pred)\n",
    "\n",
    "# test set scores\n",
    "\n",
    "y_pred = random_search.predict(X_test)\n",
    "\n",
    "print('Test set scores:')\n",
    "\n",
    "print_class_scores(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes we could improve the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set scores:\n",
      "Accuracy:  0.9583333333333334\n",
      "Precision:  0.9599832390530064\n",
      "Recall:  0.9583333333333334\n",
      "F1:  0.9582746570698378\n",
      "Test set scores:\n",
      "Accuracy:  0.9333333333333333\n",
      "Precision:  0.9444444444444445\n",
      "Recall:  0.9333333333333333\n",
      "F1:  0.9326599326599326\n"
     ]
    }
   ],
   "source": [
    "# Knn\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# define model\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "steps = [('scaler', StandardScaler()), ('model', model)]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# evaluate on train set\n",
    "\n",
    "y_pred = pipeline.predict(X_train)\n",
    "\n",
    "print('Train set scores:')\n",
    "\n",
    "print_class_scores(y_train, y_pred)\n",
    "\n",
    "# evaluate on test set\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print('Test set scores:')\n",
    "\n",
    "print_class_scores(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have good results even with a KNN, let's see if we can improve them with a randomized search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Train set scores:\n",
      "Accuracy:  0.9583333333333334\n",
      "Precision:  0.9585157390035438\n",
      "Recall:  0.9583333333333334\n",
      "F1:  0.9583268218992551\n",
      "Test set scores:\n",
      "Accuracy:  0.9666666666666667\n",
      "Precision:  0.9696969696969696\n",
      "Recall:  0.9666666666666667\n",
      "F1:  0.9665831244778613\n"
     ]
    }
   ],
   "source": [
    "# randomized search\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# define parameter grid knn\n",
    "\n",
    "param_grid = {\n",
    "    'model__n_neighbors': [3, 5, 7],  # Number of neighbors\n",
    "    'model__weights': ['uniform', 'distance'],  # Weight function\n",
    "    'model__p': [1, 2],  # Power parameter for the Minkowski metric\n",
    "}\n",
    "\n",
    "# define randomized search\n",
    "\n",
    "random_search = RandomizedSearchCV(pipeline, param_grid, cv=3, n_jobs=-1, verbose=1, scoring='accuracy', n_iter=10)\n",
    "\n",
    "# fit model\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# train set scores\n",
    "\n",
    "y_pred = random_search.predict(X_train)\n",
    "\n",
    "print('Train set scores:')\n",
    "\n",
    "print_class_scores(y_train, y_pred)\n",
    "\n",
    "# test set scores\n",
    "\n",
    "y_pred = random_search.predict(X_test)\n",
    "\n",
    "print('Test set scores:')\n",
    "\n",
    "print_class_scores(y_test, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We improved the results a little bit."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
